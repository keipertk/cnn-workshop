{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "cnn.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjwqSojq1MHj"
      },
      "source": [
        "Let's examine our Google Colab runtime. What kind of GPU and CPU did we get?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgWk8VWXzjbr"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwCDYJv1zrtL"
      },
      "source": [
        "!lscpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmJGjU7FvOQZ"
      },
      "source": [
        "# Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cn9uhpm0vOQa"
      },
      "source": [
        "This notebook follows along with the lecture on your first DNN.\n",
        "\n",
        "For this lecture we're going to use the MNIST data set (link). This is a set of 28x8 grayscale images o single digits 0 to 9.\n",
        "\n",
        "We're going to examine 3 network models. The first is a FCN (Fully Connected Network). The second is simple convolutional model. The third is a more complicated CNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKTQFEsKvOQa",
        "outputId": "f3aa6c79-5d9c-48f2-e0ee-323579161dd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"Number of GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.4.1\n",
            "Number of GPUs Available:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgqAXkfJvOQb",
        "outputId": "a6a4080f-c5b0-4cdb-cb8a-175042662c2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# import tf.keras as keras\n",
        "print(tf.keras.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d71vX5-gvOQb"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cecC49VgvOQb"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6i4D0pTvOQc"
      },
      "source": [
        "## MNIST Data Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2m32cb2bvOQc"
      },
      "source": [
        "The first model borrows from what we learned in the First NN lecture. It is a simple FCN model. To see what the MNIST dataset looks like, we can load the data set and plot the first 4 images of the training set.\n",
        "\n",
        "Note that the data set is stored in an AWS S3 bucket so when you first download it, it might take a few minutes.\n",
        "\n",
        "Also not that you may have to run the call below twice to get the images to appear."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgYAH1fLvOQc",
        "outputId": "c3db63d7-4e78-44ed-a3df-d7cfc7af45c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "# Plot ad hoc mnist instances\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# load (downloaded if needed) the MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# plot 4 images as gray scale\n",
        "plt.subplot(221)\n",
        "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(222)\n",
        "plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(223)\n",
        "plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(224)\n",
        "plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "temK5qD3vOQc"
      },
      "source": [
        "## FCN Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvZ3IRMRvOQc"
      },
      "source": [
        "Let's use a fixed random number seed for reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2FEfFVJvOQd"
      },
      "source": [
        "# fix random seed for reproducibility\n",
        "import numpy\n",
        "\n",
        "seed = 7\n",
        "numpy.random.seed(seed)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jae_zq0XvOQd"
      },
      "source": [
        "Next, load the data into the training data set and the test data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PIoS7I8vOQd"
      },
      "source": [
        "# load data\n",
        "import tensorflow as tf\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWqORTgFvOQd"
      },
      "source": [
        "We need to flatten the images (they are 2D) into a 1D vector to use a FCN model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzNRIhbTvOQd"
      },
      "source": [
        "# flatten 28*28 images to a 784 vector for each image\n",
        "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
        "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNeuO0xAvOQd"
      },
      "source": [
        "Let's normalize the input since we kwow it has to range from 0 to 255."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRX9BWf3vOQd"
      },
      "source": [
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWhplAq7vOQe"
      },
      "source": [
        "A one hot encode is needed since we have more than one class. This puts each output from 0 to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tf0qZ8HlvOQe"
      },
      "source": [
        "# one hot encode outputs\n",
        "import tensorflow as tf\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uV2cjICivOQe"
      },
      "source": [
        "The model is defined in a routine for this code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnLqAbOTvOQe"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# define baseline model\n",
        "def baseline_model():\n",
        "    # create model\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal',\n",
        "                                    activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
        "    # Compile model\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model\n",
        "# end def"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKVduMhSvOQe"
      },
      "source": [
        "Finaly we can create the model, train it, compute the final scores, and print the first one (as a check)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3NYJMxEvOQe",
        "outputId": "727934c0-54e6-48c2-dcec-29d0d744aa3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# build the model\n",
        "model = baseline_model()\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 784)               615440    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                7850      \n",
            "=================================================================\n",
            "Total params: 623,290\n",
            "Trainable params: 623,290\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "300/300 - 1s - loss: 0.2753 - accuracy: 0.9217 - val_loss: 0.1345 - val_accuracy: 0.9610\n",
            "Epoch 2/10\n",
            "300/300 - 1s - loss: 0.1107 - accuracy: 0.9684 - val_loss: 0.0997 - val_accuracy: 0.9692\n",
            "Epoch 3/10\n",
            "300/300 - 1s - loss: 0.0708 - accuracy: 0.9796 - val_loss: 0.0838 - val_accuracy: 0.9743\n",
            "Epoch 4/10\n",
            "300/300 - 1s - loss: 0.0505 - accuracy: 0.9852 - val_loss: 0.0727 - val_accuracy: 0.9782\n",
            "Epoch 5/10\n",
            "300/300 - 1s - loss: 0.0372 - accuracy: 0.9894 - val_loss: 0.0699 - val_accuracy: 0.9776\n",
            "Epoch 6/10\n",
            "300/300 - 1s - loss: 0.0272 - accuracy: 0.9930 - val_loss: 0.0659 - val_accuracy: 0.9787\n",
            "Epoch 7/10\n",
            "300/300 - 1s - loss: 0.0191 - accuracy: 0.9952 - val_loss: 0.0611 - val_accuracy: 0.9807\n",
            "Epoch 8/10\n",
            "300/300 - 1s - loss: 0.0145 - accuracy: 0.9968 - val_loss: 0.0638 - val_accuracy: 0.9801\n",
            "Epoch 9/10\n",
            "300/300 - 1s - loss: 0.0107 - accuracy: 0.9979 - val_loss: 0.0595 - val_accuracy: 0.9826\n",
            "Epoch 10/10\n",
            "300/300 - 1s - loss: 0.0080 - accuracy: 0.9987 - val_loss: 0.0589 - val_accuracy: 0.9821\n",
            "Baseline Error: 1.79%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9plLV1XAvOQf"
      },
      "source": [
        "You can create the entire code by combining the previous cells."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qkunOBMvOQf"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyHy9gYKvOQf"
      },
      "source": [
        "## Simple Convolutional Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fuh3qPP5vOQf"
      },
      "source": [
        "A convolutional Model will require additional modules to load. Again, let's use a\n",
        "fixed random number seed for reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrOfSD0UvOQf"
      },
      "source": [
        "# fix random seed for reproducibility\n",
        "import numpy\n",
        "\n",
        "seed = 7\n",
        "numpy.random.seed(seed)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxxdUvdHvOQf"
      },
      "source": [
        "Load the data set and reshape the input so that it can be loaded correctly. It also allows you to adjust to the FP32 data type which is the default or Keras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzvNfCbWvOQf",
        "outputId": "c258e62c-fcbc-458d-8351-009276ffcb8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# reshape to be [samples][pixels][width][height]\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXcI48bnvOQf"
      },
      "source": [
        "The inputs are normalized (0 to 255) and the outputs are one hot encoded (more than one class)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AX2gINhsvOQg"
      },
      "source": [
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "\n",
        "# one hot encode outputs\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zWJjFxYvOQg"
      },
      "source": [
        "The model is again created in a routine. Notice the new layers (conv2D) as well as softmax decode layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvdcPO3LvOQg"
      },
      "source": [
        "def baseline_model():\n",
        "    # create model\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.Conv2D(32, (5, 5), input_shape=(1, 28, 28), data_format = 'channels_first',\n",
        "                                     activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.2))\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
        "    # Compile model\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model\n",
        "# end def\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjuWwszRvOQg"
      },
      "source": [
        "Finaly we can create the model, train it, compute the final scores, and print the first one (as a check)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkL-NvSMvOQh",
        "outputId": "b08b6d69-e9c8-4ad2-8a9e-c85bd506afb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# build the model\n",
        "model = baseline_model()\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))\n",
        "\n",
        "# To fix problem:\n",
        "# https://github.com/keras-team/keras/issues/7611\n",
        "# https://stackoverflow.com/questions/45645276/negative-dimension-size-caused-by-subtracting-3-from-1-for-conv2d-2-convolution/45647715#45647715\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 24, 24)        832       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 12, 24)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16, 12, 24)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               589952    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 592,074\n",
            "Trainable params: 592,074\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "300/300 - 8s - loss: 0.2800 - accuracy: 0.9190 - val_loss: 0.1074 - val_accuracy: 0.9673\n",
            "Epoch 2/10\n",
            "300/300 - 1s - loss: 0.0867 - accuracy: 0.9739 - val_loss: 0.0607 - val_accuracy: 0.9793\n",
            "Epoch 3/10\n",
            "300/300 - 1s - loss: 0.0568 - accuracy: 0.9831 - val_loss: 0.0449 - val_accuracy: 0.9855\n",
            "Epoch 4/10\n",
            "300/300 - 1s - loss: 0.0430 - accuracy: 0.9867 - val_loss: 0.0429 - val_accuracy: 0.9858\n",
            "Epoch 5/10\n",
            "300/300 - 1s - loss: 0.0346 - accuracy: 0.9900 - val_loss: 0.0378 - val_accuracy: 0.9871\n",
            "Epoch 6/10\n",
            "300/300 - 1s - loss: 0.0285 - accuracy: 0.9909 - val_loss: 0.0368 - val_accuracy: 0.9871\n",
            "Epoch 7/10\n",
            "300/300 - 1s - loss: 0.0231 - accuracy: 0.9925 - val_loss: 0.0372 - val_accuracy: 0.9881\n",
            "Epoch 8/10\n",
            "300/300 - 1s - loss: 0.0188 - accuracy: 0.9939 - val_loss: 0.0416 - val_accuracy: 0.9861\n",
            "Epoch 9/10\n",
            "300/300 - 1s - loss: 0.0155 - accuracy: 0.9948 - val_loss: 0.0411 - val_accuracy: 0.9866\n",
            "Epoch 10/10\n",
            "300/300 - 1s - loss: 0.0128 - accuracy: 0.9960 - val_loss: 0.0352 - val_accuracy: 0.9881\n",
            "CNN Error: 1.19%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MO-b8r7rvOQh"
      },
      "source": [
        "Runs slower. A little bit smaller error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m11UnlrSvOQh"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUiVxaAJvOQh"
      },
      "source": [
        "## More comprehensive Convolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8lvj4UOvOQh"
      },
      "source": [
        "The simple convolution got better accuracy than FCN for the same number of epochs. Let's add some more conv2D layers to see if accuracy is improved.\n",
        "\n",
        "The first steps are combined below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-mwp8ntvOQh"
      },
      "source": [
        "# Larger CNN for the MNIST Dataset\n",
        "import numpy\n",
        "import tensorflow as tf\n",
        "\n",
        "#from keras.datasets import mnist\n",
        "#from keras.models import Sequential\n",
        "#from keras.layers import Dense\n",
        "#from keras.layers import Dropout\n",
        "#from keras.layers import Flatten\n",
        "#from keras.layers.convolutional import Conv2D\n",
        "#from keras.layers.convolutional import MaxPooling2D\n",
        "#from keras.utils import np_utils\n",
        "#from keras import backend as K\n",
        "#K.set_image_dim_ordering('th')\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# reshape to be [samples][pixels][width][height]\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n",
        "\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "\n",
        "# one hot encode outputs\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwZwG7DmvOQi"
      },
      "source": [
        "In the routine for defining model, notice we've added a 2D pooling layer and another FCN layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iotur32vOQi"
      },
      "source": [
        "# define the larger model\n",
        "def larger_model():\n",
        "    # create model\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.Conv2D(30, (5, 5), input_shape=(1, 28, 28), data_format = 'channels_first',\n",
        "                                     activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(tf.keras.layers.Conv2D(15, (3, 3), data_format = 'channels_first', activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.2))\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
        "    # Compile model\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model\n",
        "# end def"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyYvBSXvvOQi"
      },
      "source": [
        "Finaly we can create the model, train it, compute the final scores, and print the first one (as a check)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-HpQGBcvOQi"
      },
      "source": [
        "# build the model\n",
        "model = larger_model()\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n",
        "\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Large CNN Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEFzTNcvvOQi"
      },
      "source": [
        "Notice that the error (loss) is better than both of the previous networks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQmSx9KSvOQj"
      },
      "source": [
        "# Larger CNN for the MNIST Dataset\n",
        "import numpy\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#from keras.datasets import mnist\n",
        "#from keras.models import Sequential\n",
        "#from keras.layers import Dense\n",
        "#from keras.layers import Dropout\n",
        "#from keras.layers import Flatten\n",
        "#from keras.layers.convolutional import Conv2D\n",
        "#from keras.layers.convolutional import MaxPooling2D\n",
        "#from keras.utils import np_utils\n",
        "#from keras import backend as K\n",
        "#import matplotlib.pyplot as plt\n",
        "#K.set_image_dim_ordering('th')\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# reshape to be [samples][pixels][width][height]\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n",
        "\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "\n",
        "# one hot encode outputs\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "\n",
        "# define the larger model\n",
        "def larger_model():\n",
        "    # create model\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.Conv2D(30, (5, 5), input_shape=(1, 28, 28), data_format = 'channels_first',\n",
        "                                     activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(tf.keras.layers.Conv2D(15, (3, 3), data_format = 'channels_first', activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.2))\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
        "    # Compile model\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model\n",
        "# end def\n",
        "\n",
        "# build the model\n",
        "model = larger_model()\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n",
        "\n",
        "# Evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Large CNN Error: %.2f%%\" % (100-scores[1]*100))\n",
        "print(\" \")\n",
        "\n",
        "# Inference on random image\n",
        "img_class = model.predict_classes(X_test)\n",
        "\n",
        "prediction = img_class[130]\n",
        "print(\"X_test[130] = \",prediction)\n",
        "\n",
        "img = X_test[130]\n",
        "test_img = img.reshape((1,784))\n",
        "\n",
        "img = img.reshape((28,28))\n",
        "plt.imshow(img)\n",
        "plt.title(str(prediction))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}